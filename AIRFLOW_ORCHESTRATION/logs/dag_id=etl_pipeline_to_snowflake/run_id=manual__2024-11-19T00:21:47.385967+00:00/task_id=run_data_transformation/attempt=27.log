[2024-11-19T21:18:29.308+0100] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-11-19T21:18:29.341+0100] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_pipeline_to_snowflake.run_data_transformation manual__2024-11-19T00:21:47.385967+00:00 [queued]>
[2024-11-19T21:18:29.364+0100] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_pipeline_to_snowflake.run_data_transformation manual__2024-11-19T00:21:47.385967+00:00 [queued]>
[2024-11-19T21:18:29.368+0100] {taskinstance.py:2865} INFO - Starting attempt 27 of 27
[2024-11-19T21:18:29.422+0100] {taskinstance.py:2888} INFO - Executing <Task(PythonOperator): run_data_transformation> on 2024-11-19 00:21:47.385967+00:00
[2024-11-19T21:18:29.444+0100] {standard_task_runner.py:72} INFO - Started process 242235 to run task
[2024-11-19T21:18:29.449+0100] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'etl_pipeline_to_snowflake', 'run_data_transformation', 'manual__2024-11-19T00:21:47.385967+00:00', '--job-id', '81', '--raw', '--subdir', 'DAGS_FOLDER/staging_data_dag.py', '--cfg-path', '/tmp/tmpx03sbzku']
[2024-11-19T21:18:29.451+0100] {standard_task_runner.py:105} INFO - Job 81: Subtask run_data_transformation
[2024-11-19T21:18:29.697+0100] {task_command.py:467} INFO - Running <TaskInstance: etl_pipeline_to_snowflake.run_data_transformation manual__2024-11-19T00:21:47.385967+00:00 [running]> on host zainab.
[2024-11-19T21:18:29.864+0100] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='etl_pipeline_to_snowflake' AIRFLOW_CTX_TASK_ID='run_data_transformation' AIRFLOW_CTX_EXECUTION_DATE='2024-11-19T00:21:47.385967+00:00' AIRFLOW_CTX_TRY_NUMBER='27' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-19T00:21:47.385967+00:00'
[2024-11-19T21:18:29.870+0100] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-11-19T21:18:29.873+0100] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-11-19T21:18:29.875+0100] {logging_mixin.py:190} INFO - Current task name:run_data_transformation state:running start_date:2024-11-19 20:18:29.344384+00:00
[2024-11-19T21:18:29.877+0100] {logging_mixin.py:190} INFO - Dag name:etl_pipeline_to_snowflake and current dag run status:running
[2024-11-19T21:18:29.879+0100] {taskinstance.py:731} INFO - ::endgroup::
[2024-11-19T21:18:30.368+0100] {transform.py:36} INFO - Transformation complete.
[2024-11-19T21:18:30.391+0100] {base.py:84} INFO - Retrieving connection 'snowflake_conn_id'
[2024-11-19T21:18:30.394+0100] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.12, Platform: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
[2024-11-19T21:18:30.397+0100] {connection.py:1197} INFO - Connecting to GLOBAL Snowflake domain
[2024-11-19T21:18:30.402+0100] {connection.py:1278} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-19T21:18:40.458+0100] {cursor.py:1166} INFO - Number of results in first chunk: 1
[2024-11-19T21:18:40.502+0100] {sql.py:553} INFO - Running statement: SELECT COUNT(*) 
    FROM information_schema.tables 
    WHERE table_schema = 'staging' 
    AND table_name = 'country_data';, parameters: None
[2024-11-19T21:18:41.269+0100] {cursor.py:1166} INFO - Number of results in first chunk: 1
[2024-11-19T21:18:41.401+0100] {sql.py:562} INFO - Rows affected: 1
[2024-11-19T21:18:41.411+0100] {snowflake.py:447} INFO - Rows affected: 1
[2024-11-19T21:18:41.509+0100] {snowflake.py:448} INFO - Snowflake query id: 01b87b82-0203-b010-0000-0003159ef4e9
[2024-11-19T21:18:41.805+0100] {cursor.py:1166} INFO - Number of results in first chunk: 1
[2024-11-19T21:18:41.812+0100] {connection.py:789} INFO - closed
[2024-11-19T21:18:42.229+0100] {connection.py:795} INFO - No async queries seem to be running, deleting session
[2024-11-19T21:18:42.745+0100] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.3, Python Version: 3.10.12, Platform: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
[2024-11-19T21:18:42.750+0100] {connection.py:1197} INFO - Connecting to GLOBAL Snowflake domain
[2024-11-19T21:18:42.757+0100] {connection.py:1278} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-19T21:18:45.873+0100] {cursor.py:1166} INFO - Number of results in first chunk: 1
[2024-11-19T21:18:45.967+0100] {sql.py:553} INFO - Running statement: CREATE TABLE staging.country_data (
            Country_Name STRING, Independence STRING, UN_Member STRING, Start_of_Week STRING, Official_Name STRING, Common_Native_Name STRING, Currency_Code STRING, Currency_Name STRING, Currency_Symbol STRING, Country_Code STRING, Capital STRING, Region STRING, Sub_Region STRING, Languages STRING, Area STRING, Population STRING, Continents STRING,  -- Assuming all columns are STRING, adjust accordingly
            created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
            updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
        );, parameters: None
[2024-11-19T21:18:47.500+0100] {connection.py:789} INFO - closed
[2024-11-19T21:18:47.833+0100] {connection.py:795} INFO - No async queries seem to be running, deleting session
[2024-11-19T21:18:48.785+0100] {taskinstance.py:3310} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/capstone_project/airflow/dags/scripts/transform.py", line 95, in run_transformation
    load_function(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/capstone_project/airflow/dags/scripts/load.py", line 85, in load_data_to_snowflake
    snowflake_hook.run(create_table_query)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 435, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py", line 558, in _run_command
    cur.execute(sql_statement)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1097, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002002 (42710): 01b87b82-0203-b010-0000-0003159ef4f1: SQL compilation error:
Object 'STAGING.COUNTRY_DATA' already exists.
[2024-11-19T21:18:49.287+0100] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-11-19T21:18:49.290+0100] {logging_mixin.py:190} INFO - Task start:2024-11-19 20:18:29.344384+00:00 end:2024-11-19 20:18:49.286754+00:00 duration:19.94237
[2024-11-19T21:18:49.293+0100] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): run_data_transformation> dag:<DAG: etl_pipeline_to_snowflake> dagrun:<DagRun etl_pipeline_to_snowflake @ 2024-11-19 00:21:47.385967+00:00: manual__2024-11-19T00:21:47.385967+00:00, state:running, queued_at: 2024-11-19 20:08:14.260996+00:00. externally triggered: True>
[2024-11-19T21:18:49.295+0100] {logging_mixin.py:190} INFO - Failure caused by 002002 (42710): 01b87b82-0203-b010-0000-0003159ef4f1: SQL compilation error:
Object 'STAGING.COUNTRY_DATA' already exists.
[2024-11-19T21:18:49.297+0100] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline_to_snowflake, task_id=run_data_transformation, run_id=manual__2024-11-19T00:21:47.385967+00:00, execution_date=20241119T002147, start_date=20241119T201829, end_date=20241119T201849
[2024-11-19T21:18:50.309+0100] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-11-19T21:18:50.312+0100] {standard_task_runner.py:124} ERROR - Failed to execute job 81 for task run_data_transformation (002002 (42710): 01b87b82-0203-b010-0000-0003159ef4f1: SQL compilation error:
Object 'STAGING.COUNTRY_DATA' already exists.; 242235)
Traceback (most recent call last):
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/utils/cli.py", line 115, in wrapper
    return f(*args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3004, in _run_raw_task
    return _run_raw_task(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3158, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3182, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/capstone_project/airflow/dags/scripts/transform.py", line 95, in run_transformation
    load_function(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/capstone_project/airflow/dags/scripts/load.py", line 85, in load_data_to_snowflake
    snowflake_hook.run(create_table_query)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 435, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/airflow/providers/common/sql/hooks/sql.py", line 558, in _run_command
    cur.execute(sql_statement)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1097, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/mnt/c/Users/zaina/Documents/Core_Data_Engineering/airflow/airflow_coresentiment_Data_pipeline/airflow/lib/python3.10/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002002 (42710): 01b87b82-0203-b010-0000-0003159ef4f1: SQL compilation error:
Object 'STAGING.COUNTRY_DATA' already exists.
[2024-11-19T21:18:50.384+0100] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2024-11-19T21:18:50.412+0100] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-19T21:18:50.437+0100] {local_task_job_runner.py:245} INFO - ::endgroup::
